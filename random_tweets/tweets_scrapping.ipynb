{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc6a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required modules\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf809df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "my_pass=getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "662de39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the driver instance\n",
    "s=Service('/home/talha/Softwares/chromedriver_linux64/chromedriver')\n",
    "myoptions = Options()\n",
    "driver = Chrome(service=s, options=myoptions)\n",
    "driver.maximize_window()\n",
    "\n",
    "#getting the twitter login page\n",
    "driver.get('https://twitter.com/login')\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "#giving login credentials\n",
    "time.sleep(2)\n",
    "username = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//input[@name=\"text\"]'))) \n",
    "username.send_keys('TalhaMalik1357')\n",
    "username.send_keys(Keys.ENTER) \n",
    "time.sleep(2)\n",
    "passwd = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.XPATH, '//input[@name=\"password\"]')))\n",
    "passwd.send_keys(my_pass) # actual passwd is saved in an environment variable :)\n",
    "passwd.send_keys(Keys.ENTER)\n",
    "\n",
    "#getting tweets to be scrapped\n",
    "time.sleep(2)\n",
    "search_input = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH,'//input[@aria-label=\"Search query\"]')))\n",
    "search_input.send_keys(\"Shah Mehmood Qureshi\")\n",
    "time.sleep(2)\n",
    "search_input.send_keys(Keys.ENTER)\n",
    "\n",
    "#locating to people tag to get shah mehmood qureshi's account in the list of accounts\n",
    "time.sleep(2)\n",
    "people = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.LINK_TEXT, 'People')))\n",
    "people.click()\n",
    "\n",
    "\n",
    "#getting shah sab's official page opened\n",
    "time.sleep(2)\n",
    "get_shah_jee = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[2]/div/section/div/div/div[1]/div/div/div/div/div[2]/div[1]/div[1]/div/div[1]/a/div/div[1]/span/span')))\n",
    "get_shah_jee.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0a0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now scrap the tweets just scrapping 50 tweets for sample as i dont have to use this data set for my nlp task\n",
    "articles = []\n",
    "tweet_list= []\n",
    "time_list=[]\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    article = driver.find_elements(By.TAG_NAME,'article')\n",
    "    for a in article:\n",
    "        if a not in articles:\n",
    "            tweet = a.find_element(By.XPATH, './/*[@data-testid=\"tweetText\"]')\n",
    "            articles.append(a)\n",
    "            t = a.find_element(By.XPATH,'.//time')\n",
    "            time_list.append(t.text)\n",
    "            tweet_list.append(tweet.text)\n",
    "    if len(tweet_list) >=50:\n",
    "        break\n",
    "    driver.execute_script(\"window.scrollBy(0,500);\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce1d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the scrapped tweets and thier time to the dataframe\n",
    "\n",
    "data = {'Time':time_list,'Tweet':tweet_list}\n",
    "df = pd.DataFrame(data, columns=['Time','Tweet'])\n",
    "df\n",
    "\n",
    "#sending data from dataframe to a csv file \n",
    "df.to_csv('tweets.csv', index=True)\n",
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
